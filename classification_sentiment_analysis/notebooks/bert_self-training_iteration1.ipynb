{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert_self-training_iteration1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"ADk1Bo3of46K","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"adfd4cf6-a770-4add-d35e-ff72ac6f874c"},"source":["!pip3 install ktrain"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting ktrain\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/c0/695334957b2774a36b79b8451f0da6b003f20580f47c1b4dc8f854e84fae/ktrain-0.17.3.tar.gz (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 128kB/s \n","\u001b[?25hCollecting tensorflow==2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 23kB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.4.1)\n","Collecting scikit-learn==0.21.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 45kB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.5)\n","Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.2.3)\n","Collecting keras_bert>=0.81.0\n","  Downloading https://files.pythonhosted.org/packages/ec/08/bffa03eb899b20bfb60553e4503f8bac00b83d415bc6ead08f6b447e8aaa/keras-bert-0.84.0.tar.gz\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.15.1)\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n","\u001b[K     |████████████████████████████████| 983kB 36.6MB/s \n","\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n","Collecting cchardet==2.1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/4e/847feebfc3e71c773b23ee06c74687b8c50a5a6d6aaff452a0a4f4eb9a32/cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241kB)\n","\u001b[K     |████████████████████████████████| 245kB 41.4MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.4)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.4.0)\n","Collecting seqeval\n","  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.4)\n","Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.0)\n","Collecting transformers>=2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 31.7MB/s \n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n","Collecting syntok\n","  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n","Collecting whoosh\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n","\u001b[K     |████████████████████████████████| 471kB 34.9MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.10.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.18.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.2.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.2)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.30.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 33.3MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.34.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert>=0.81.0->ktrain) (2.3.1)\n","Collecting keras-transformer>=0.37.0\n","  Downloading https://files.pythonhosted.org/packages/8a/2b/c465241bd3f37a3699246827ff4ad7974c6edeaa69cf9cdcff2fd1d3ba46/keras-transformer-0.37.0.tar.gz\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n","Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.11.2)\n","Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n","Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (7.0.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (19.3.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.3.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (4.41.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.22.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (2019.12.20)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 33.3MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 34.8MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 33.4MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->ktrain) (0.7)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (47.3.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.1.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.7.0\n","  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n","Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->ktrain) (1.52.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.11.0->ktrain) (7.1.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.1.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.6.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n","Building wheels for collected packages: ktrain, keras-bert, langdetect, seqeval, syntok, gast, keras-transformer, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ktrain: filename=ktrain-0.17.3-cp36-none-any.whl size=25249269 sha256=8551ee8fc76ed06a82219e6239dc1e650e282a1089fb0117b52bfa9c4511db56\n","  Stored in directory: /root/.cache/pip/wheels/24/87/78/8dcbc028acc22bc106e03a954f0de2f02e57fb42438ecb177d\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.84.0-cp36-none-any.whl size=36139 sha256=ef1e0fc97082d57e7f8b91276fa0ba84eedeac1a66595db5f62cda6b19f9a6ad\n","  Stored in directory: /root/.cache/pip/wheels/1f/59/04/12e95257aebfd27f7edaaf65ab7dd57b5f6cadfb183f1a4ccd\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=23b18a809b0b097686e16748fd8b1f388d737d5183200232f1a6c8942dd180fa\n","  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=1da6e8a869a671b95b1202d7a23f48acdb3ef15380270228c61c6f5f8e56a51d\n","  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n","  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20918 sha256=bd51e04c610247502dc5d2ec1e045c37dcadbaa894e70d13f7be70c5a5c2c9d7\n","  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=05844bb9301b26e80939124843551511deee9f5682964c0610bd3509e24b8fc7\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.37.0-cp36-none-any.whl size=12942 sha256=a3c286dd8d8bd0e2835dc7f6113c9d2484639d23ffdacc65d5a6ae3bc83fad74\n","  Stored in directory: /root/.cache/pip/wheels/2a/f9/31/2a3289e948852ce0dd3fcd94c34bbc7eb9628842cb7110a87b\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=7970538e1f1885ea5abda271761cc9a7a2dde529bb0b87ecf6f13c340f544943\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=3dcfc1c4cf6264ded77c1ce82377b0a32822f699af5c51f47318508e2a9c4cef\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15611 sha256=2118849d3f375c32a4c9ad012c990de4f9e657eb61a4297fde666f6d2356608a\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=30c63e5f16d64562718b77fa099d163d120255b6da93c00c2f2c23581dcf2550\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=ecc0876e7f82a31992e0a64b8995f0be672031f227abbcc70d73e5d347056aea\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=284563a29744cf9044db6e957937cc5a31d6aceb5e94585ecf8bc449d2c1e717\n","  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=b73c823aebea386327163d8a50f33475ca073879e670f7e66b767045265125f9\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built ktrain keras-bert langdetect seqeval syntok gast keras-transformer sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow, scikit-learn, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, tokenizers, sacremoses, sentencepiece, transformers, syntok, whoosh, ktrain\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: tensorflow 2.2.0\n","    Uninstalling tensorflow-2.2.0:\n","      Successfully uninstalled tensorflow-2.2.0\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed cchardet-2.1.5 gast-0.2.2 keras-bert-0.84.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.37.0 ktrain-0.17.3 langdetect-1.0.8 sacremoses-0.0.43 scikit-learn-0.21.3 sentencepiece-0.1.91 seqeval-0.0.12 syntok-1.3.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tokenizers-0.8.0rc4 transformers-3.0.0 whoosh-2.7.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G054WZ_yo9qT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c92d09a3-3e36-4c1d-c90d-c08e3186f9fd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j7nyCdo2f8Vv","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","\n","import ktrain\n","from ktrain import text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GvaHwd4jgMf6","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"201f1872-6389-4793-b223-e7048e6917ac"},"source":["import nltk\n","import bs4\n","import re\n","#nltk.download('stopwords')\n","nltk.download('punkt')\n","#from nltk.corpus import stopwords\n","#from nltk.tokenize import word_tokenize\n","#stop_words = set(stopwords.words('english'))\n","def clean_tweet(tweet):\n","  tweet=bs4.BeautifulSoup(tweet,'lxml').get_text()\n","  tweet=re.sub(r'@[A-Za-z0-9]+',' ',tweet)\n","  tweet=re.sub(r'https?://[A-Za-z0-9./]+',' ',tweet)\n","  tweet = re.sub(r'&amp;', '&', tweet)\n","  #tweet=re.sub(r\"[^a-zA-Z']\",' ',tweet)\n","  tweet=re.sub(r\" +\",\" \",tweet)\n","  tweet=tweet.strip()\n","  #tweet=tweet.lower()\n","  #word_tokens = word_tokenize(tweet)\n","  #filtered_tweet = [w for w in word_tokens if not w in stop_words]\n","  #return ' '.join(filtered_tweet)\n","  return tweet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6EAQXxc6gr13","colab":{}},"source":["data_train = pd.read_csv('/content/drive/My Drive/IBM_sentiment_analysis/classification_sentiment_analysis/datasets/self-training_iteration1_data/train_f_n.csv', encoding='utf-8')\n","data_test = pd.read_csv('/content/drive/My Drive/IBM_sentiment_analysis/classification_sentiment_analysis/datasets/self-training_iteration1_data/test_f_n.csv', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LAQnDyc7g4ze","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"596c35e3-8f3e-472c-8e39-85b6c1869eba"},"source":["print(data_train.shape)\n","print(data_test.shape)\n","print(data_train.isnull().sum())\n","print(data_test.isnull().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(11231, 2)\n","(3744, 2)\n","Emotion    0\n","Text       0\n","dtype: int64\n","Emotion    0\n","Text       0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v6RhnhZFhDT_","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"5bc56a70-08b4-46f1-d2da-bdffcfc8f98e"},"source":["data_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>anger</td>\n","      <td>When I heard that I was not to be provided wit...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>@GoPro your UX online is appalling! No clear s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>We'll get to go fishing at the river . I hate...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>joy</td>\n","      <td>Hi , Mary , long time no see .</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>To my great annoyance I found myself jealous .</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion                                               Text\n","0    anger  When I heard that I was not to be provided wit...\n","1  sadness  @GoPro your UX online is appalling! No clear s...\n","2  sadness   We'll get to go fishing at the river . I hate...\n","3      joy                    Hi , Mary , long time no see . \n","4    anger    To my great annoyance I found myself jealous . "]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O29Jm_vkhLAv","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"091d431c-cb2c-45d1-9708-9c8b430fa9bf"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>Next june .</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fear</td>\n","      <td>Awesome time at @teamoneill 's Fighting Fear p...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>anger</td>\n","      <td>@o2academybham since when the fuck can you not...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>anger</td>\n","      <td>Losing the will 2 live with @virginmedia busin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>A whole crowd of us went to a folklore festiva...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion                                               Text\n","0  neutral                                       Next june . \n","1     fear  Awesome time at @teamoneill 's Fighting Fear p...\n","2    anger  @o2academybham since when the fuck can you not...\n","3    anger  Losing the will 2 live with @virginmedia busin...\n","4    anger  A whole crowd of us went to a folklore festiva..."]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qxGeaWxphOT7","colab":{}},"source":["data_train['cleaned']=data_train['Text'].apply(clean_tweet)\n","data_test['cleaned']=data_test['Text'].apply(clean_tweet)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4EsOvDe8hmJV","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"ab216292-89af-405c-ee39-149ff3c6f4d8"},"source":["data_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","      <th>cleaned</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>anger</td>\n","      <td>When I heard that I was not to be provided wit...</td>\n","      <td>When I heard that I was not to be provided wit...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>@GoPro your UX online is appalling! No clear s...</td>\n","      <td>your UX online is appalling! No clear save but...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>We'll get to go fishing at the river . I hate...</td>\n","      <td>We'll get to go fishing at the river . I hate ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>joy</td>\n","      <td>Hi , Mary , long time no see .</td>\n","      <td>Hi , Mary , long time no see .</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>To my great annoyance I found myself jealous .</td>\n","      <td>To my great annoyance I found myself jealous .</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion  ...                                            cleaned\n","0    anger  ...  When I heard that I was not to be provided wit...\n","1  sadness  ...  your UX online is appalling! No clear save but...\n","2  sadness  ...  We'll get to go fishing at the river . I hate ...\n","3      joy  ...                     Hi , Mary , long time no see .\n","4    anger  ...     To my great annoyance I found myself jealous .\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gHboVQ8Ihpna","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"b3b16472-24c2-47af-830b-78430319dd68"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","      <th>cleaned</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>Next june .</td>\n","      <td>Next june .</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fear</td>\n","      <td>Awesome time at @teamoneill 's Fighting Fear p...</td>\n","      <td>Awesome time at 's Fighting Fear premiere last...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>anger</td>\n","      <td>@o2academybham since when the fuck can you not...</td>\n","      <td>since when the fuck can you not stand at a con...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>anger</td>\n","      <td>Losing the will 2 live with @virginmedia busin...</td>\n","      <td>Losing the will 2 live with business bb gone d...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>A whole crowd of us went to a folklore festiva...</td>\n","      <td>A whole crowd of us went to a folklore festiva...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion  ...                                            cleaned\n","0  neutral  ...                                        Next june .\n","1     fear  ...  Awesome time at 's Fighting Fear premiere last...\n","2    anger  ...  since when the fuck can you not stand at a con...\n","3    anger  ...  Losing the will 2 live with business bb gone d...\n","4    anger  ...  A whole crowd of us went to a folklore festiva...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T5PaeatqhvBO","colab":{}},"source":["data_train=data_train[data_train['cleaned']!='']\n","data_test=data_test[data_test['cleaned']!='']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"41yu3_uch4SP","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"da7457eb-7b42-4f21-82a7-503be11d2348"},"source":["print(data_train.shape)\n","print(data_test.shape)\n","print(data_train.isnull().sum())\n","print(data_test.isnull().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(11231, 3)\n","(3744, 3)\n","Emotion    0\n","Text       0\n","cleaned    0\n","dtype: int64\n","Emotion    0\n","Text       0\n","cleaned    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BpsxHFaSiCrl","colab":{"base_uri":"https://localhost:8080/","height":484},"outputId":"c5b2d33c-2a63-4cd5-b4ff-7291b8fa8c44"},"source":["X_train = data_train.cleaned.tolist()\n","X_test = data_test.cleaned.tolist()\n","\n","y_train = data_train.Emotion.tolist()\n","y_test = data_test.Emotion.tolist()\n","\n","data = data_train.append(data_test, ignore_index=True)\n","\n","class_names = ['joy', 'sadness', 'fear', 'anger', 'neutral']\n","\n","print('size of training set: %s' % (len(data_train['Text'])))\n","print('size of validation set: %s' % (len(data_test['Text'])))\n","print(data.Emotion.value_counts())\n","\n","data.head(10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["size of training set: 11231\n","size of validation set: 3744\n","fear       3148\n","joy        3049\n","anger      2952\n","sadness    2914\n","neutral    2912\n","Name: Emotion, dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","      <th>cleaned</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>anger</td>\n","      <td>When I heard that I was not to be provided wit...</td>\n","      <td>When I heard that I was not to be provided wit...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>@GoPro your UX online is appalling! No clear s...</td>\n","      <td>your UX online is appalling! No clear save but...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>We'll get to go fishing at the river . I hate...</td>\n","      <td>We'll get to go fishing at the river . I hate ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>joy</td>\n","      <td>Hi , Mary , long time no see .</td>\n","      <td>Hi , Mary , long time no see .</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>To my great annoyance I found myself jealous .</td>\n","      <td>To my great annoyance I found myself jealous .</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>anger</td>\n","      <td>I had too much homework and examinations and I...</td>\n","      <td>I had too much homework and examinations and I...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>sadness</td>\n","      <td>You know that my father is irritable .</td>\n","      <td>You know that my father is irritable .</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>joy</td>\n","      <td>It was the first time I met him (my boyfriend ...</td>\n","      <td>It was the first time I met him (my boyfriend ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>neutral</td>\n","      <td>The weather report says it's going to rain fo...</td>\n","      <td>The weather report says it's going to rain for...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>sadness</td>\n","      <td>When my basket ball team lost the qualificatio...</td>\n","      <td>When my basket ball team lost the qualificatio...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion  ...                                            cleaned\n","0    anger  ...  When I heard that I was not to be provided wit...\n","1  sadness  ...  your UX online is appalling! No clear save but...\n","2  sadness  ...  We'll get to go fishing at the river . I hate ...\n","3      joy  ...                     Hi , Mary , long time no see .\n","4    anger  ...     To my great annoyance I found myself jealous .\n","5    anger  ...  I had too much homework and examinations and I...\n","6  sadness  ...             You know that my father is irritable .\n","7      joy  ...  It was the first time I met him (my boyfriend ...\n","8  neutral  ...  The weather report says it's going to rain for...\n","9  sadness  ...  When my basket ball team lost the qualificatio...\n","\n","[10 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NC67eVH2iMzZ","colab":{}},"source":["encoding = {\n","    'joy': 0,\n","    'sadness': 1,\n","    'fear': 2,\n","    'anger': 3,\n","    'neutral': 4\n","}\n","\n","\n","y_train = [encoding[x] for x in y_train]\n","y_test = [encoding[x] for x in y_test]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rUOSAJc_iTSk","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"3bcdc016-80eb-49ba-9526-72936362fdd9"},"source":["(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n","                                                                       x_test=X_test, y_test=y_test,\n","                                                                       class_names=class_names,\n","                                                                       preprocess_mode='bert',\n","                                                                       maxlen=350, \n","                                                                       max_features=35000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["task: text classification\n","downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n","[██████████████████████████████████████████████████]\n","extracting pretrained BERT model...\n","done.\n","\n","cleanup downloaded zip...\n","done.\n","\n","preprocessing train...\n","language: en\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["done."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Is Multi-Label? False\n","preprocessing test...\n","language: en\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["done."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9I-1qaXHiaXn","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"573ccdaf-fd84-4e82-f34a-6ca80c0c734c"},"source":["model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Is Multi-Label? False\n","maxlen is 350\n","done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ak_IWuajiesB","colab":{}},"source":["learner = ktrain.get_learner(model, train_data=(x_train, y_train), \n","                             val_data=(x_test, y_test),\n","                             batch_size=6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tCNt6cYFnlFw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"outputId":"8ca17c3f-cc73-4ae0-d556-739c091f683c"},"source":["learner.fit_onecycle(2e-5, 3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","begin training using onecycle policy with max lr of 2e-05...\n","Train on 11231 samples, validate on 3744 samples\n","Epoch 1/3\n","11231/11231 [==============================] - 2325s 207ms/sample - loss: 0.8235 - accuracy: 0.6877 - val_loss: 0.5426 - val_accuracy: 0.8080\n","Epoch 2/3\n","11231/11231 [==============================] - 2327s 207ms/sample - loss: 0.3967 - accuracy: 0.8622 - val_loss: 0.4699 - val_accuracy: 0.8285\n","Epoch 3/3\n","11231/11231 [==============================] - 2325s 207ms/sample - loss: 0.1554 - accuracy: 0.9484 - val_loss: 0.5116 - val_accuracy: 0.8392\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2e502a30b8>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GKAgL2z7imfh","colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"346203ba-1ab2-4512-e189-10ec739abd33"},"source":["learner.validate(val_data=(x_test, y_test), class_names=class_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         joy       0.87      0.89      0.88       762\n","     sadness       0.80      0.83      0.82       729\n","        fear       0.86      0.81      0.84       787\n","       anger       0.81      0.83      0.82       738\n","     neutral       0.85      0.83      0.84       728\n","\n","    accuracy                           0.84      3744\n","   macro avg       0.84      0.84      0.84      3744\n","weighted avg       0.84      0.84      0.84      3744\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[676,  17,  13,   9,  47],\n","       [ 20, 603,  32,  60,  14],\n","       [ 27,  53, 641,  47,  19],\n","       [  7,  48,  40, 615,  28],\n","       [ 48,  29,  17,  27, 607]])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0Y-piV5FipIo","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e85e502f-2956-410d-cb41-ee6920f3a934"},"source":["predictor = ktrain.get_predictor(learner.model, preproc)\n","predictor.get_classes()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['joy', 'sadness', 'fear', 'anger', 'neutral']"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8FxWnOh2itTW","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6f34b1e7-6fd3-4367-856a-c6c5dc702bf7"},"source":["message = 'hell no'\n","predictor.predict(message)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'anger'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4egkBuq7i2JZ","colab":{}},"source":["predictor.save(\"/content/drive/My Drive/IBM_sentiment_analysis/classification_sentiment_analysis/models/bert_model_self-training_iteration1\")"],"execution_count":null,"outputs":[]}]}