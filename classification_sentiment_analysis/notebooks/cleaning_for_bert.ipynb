{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cleaning_for_bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JaouLwOU0Ex2","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpbFQ-4W0esR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":279},"outputId":"d08e6b3a-aadb-4ee7-f72f-955c977a13c5"},"source":["df=pd.read_csv('/content/drive/My Drive/IBM_sentiment_analysis/classification_sentiment_analysis/all_tweets.csv')\n","print(df.shape)\n","print(df.isnull().sum())\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4185573, 3)\n","date              0\n","text              0\n","retweet_count    64\n","dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>retweet_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-04-01</td>\n","      <td>@ZyppApp Corona Update in India!\\n\\nTotal Conf...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-04-01</td>\n","      <td>üì¢ Announcement\\nIn view of the current situati...</td>\n","      <td>93.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-04-01</td>\n","      <td>All 110 new #Covid19 cases in Tamil Nadu today...</td>\n","      <td>3793.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-04-01</td>\n","      <td>Great gesture. Thank you to IFFCO.  #IndiaFigh...</td>\n","      <td>3323.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-04-01</td>\n","      <td>Just In | 110 more cases test positive for #CO...</td>\n","      <td>89.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         date                                               text  retweet_count\n","0  2020-04-01  @ZyppApp Corona Update in India!\\n\\nTotal Conf...            0.0\n","1  2020-04-01  üì¢ Announcement\\nIn view of the current situati...           93.0\n","2  2020-04-01  All 110 new #Covid19 cases in Tamil Nadu today...         3793.0\n","3  2020-04-01  Great gesture. Thank you to IFFCO.  #IndiaFigh...         3323.0\n","4  2020-04-01  Just In | 110 more cases test positive for #CO...           89.0"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"z6hsoKD47XGx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"f556f578-918b-41f1-b27f-fb3c32dec177"},"source":["#BERT requires less cleaning so only removing URLs,mentions and extra spaces\n","import nltk\n","import bs4\n","import re\n","#nltk.download('stopwords')\n","nltk.download('punkt')\n","#from nltk.corpus import stopwords\n","#from nltk.tokenize import word_tokenize\n","#stop_words = set(stopwords.words('english'))\n","def clean_tweet(tweet):\n","  tweet=bs4.BeautifulSoup(tweet,'lxml').get_text()\n","  tweet=re.sub(r'@[A-Za-z0-9]+',' ',tweet)\n","  tweet=re.sub(r'https?://[A-Za-z0-9./]+',' ',tweet)\n","  tweet = re.sub(r'&amp;', '&', tweet)\n","  #tweet=re.sub(r\"[^a-zA-Z']\",' ',tweet)\n","  tweet=re.sub(r\" +\",\" \",tweet)\n","  tweet=tweet.strip()\n","  #tweet=tweet.lower()\n","  #word_tokens = word_tokenize(tweet)\n","  #filtered_tweet = [w for w in word_tokens if not w in stop_words]\n","  #return ' '.join(filtered_tweet)\n","  return tweet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gJDq4e4c7jGa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3ea6e5d6-984e-42df-d1b1-53cee0b86095"},"source":["df['cleaned']=df['text'].apply(clean_tweet)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/LtubIGUOnm\n","True...!!!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/dMl4pBBUhE¬†\n","SHARE\n","https://t.co/dMl4pBBUhE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/GjV8BpADBb\n","Interesting\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/6MA7cbh7MA\n","\n","Respect\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/oE1f97iJSx\n","\n","#Live#LookFitwithSaranya#Quarantine#StayHome#StaySafe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/qV7rQDBHHY\n","Confirmed\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/C6aFnQt9SA\n","\n","Link\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/afLthFET6t\n","Amazing‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/rklUZ6L1LL\n","\n","Fuck.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/Ee829IWc9a\n","\n","Link\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/F8kYJuTdo7\n","\n","fuckkkk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/u7Knjn5mqm\n","#Footwear#Industry#Navigation#Resolution#Branfs#,Retailers#Measures#Goverent#Trade#Stimulus#Experts#Lockdown\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/XNq4le4JcT\n","#coronavirus#covid-19#Goosebumps\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/ocBu7LxhBG\n","\n","Expected\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/YZi3ImN2LT\n","Interfron\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/HHZiZVrFz1\n","#coronavirus#COVID19#COVID19#Coronavirussurvivor\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/LKzF6AUsrf\n","\n","WHAT!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/90ArJJrpPR\n","Salute\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/hPfp1oDCj0\n","\n","CRAZY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/OthFXZpEbI\n","\n","Dictatorship\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/9sLRlGs7N2\n","COVID-19\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/vcostPwnwP\n","\n","Really?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"uznK7gkg8HB8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"0f242a71-94c6-49a4-8358-adce01fa42dc"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>retweet_count</th>\n","      <th>cleaned</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-04-01</td>\n","      <td>@ZyppApp Corona Update in India!\\n\\nTotal Conf...</td>\n","      <td>0.0</td>\n","      <td>Corona Update in India!\\n\\nTotal Confirmed: 17...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-04-01</td>\n","      <td>üì¢ Announcement\\nIn view of the current situati...</td>\n","      <td>93.0</td>\n","      <td>üì¢ Announcement\\nIn view of the current situati...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-04-01</td>\n","      <td>All 110 new #Covid19 cases in Tamil Nadu today...</td>\n","      <td>3793.0</td>\n","      <td>All 110 new #Covid19 cases in Tamil Nadu today...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-04-01</td>\n","      <td>Great gesture. Thank you to IFFCO.  #IndiaFigh...</td>\n","      <td>3323.0</td>\n","      <td>Great gesture. Thank you to IFFCO. #IndiaFight...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-04-01</td>\n","      <td>Just In | 110 more cases test positive for #CO...</td>\n","      <td>89.0</td>\n","      <td>Just In | 110 more cases test positive for #CO...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         date  ...                                            cleaned\n","0  2020-04-01  ...  Corona Update in India!\\n\\nTotal Confirmed: 17...\n","1  2020-04-01  ...  üì¢ Announcement\\nIn view of the current situati...\n","2  2020-04-01  ...  All 110 new #Covid19 cases in Tamil Nadu today...\n","3  2020-04-01  ...  Great gesture. Thank you to IFFCO. #IndiaFight...\n","4  2020-04-01  ...  Just In | 110 more cases test positive for #CO...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"jp_kcyG9unfj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"62e690a2-791b-43ab-e327-efaf7dc78950"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["date              0\n","text              0\n","retweet_count    64\n","cleaned           0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"y3Rb9mvfu7IJ","colab_type":"code","colab":{}},"source":["df.to_csv('/content/drive/My Drive/IBM_sentiment_analysis/classification_test/to_label.csv')"],"execution_count":null,"outputs":[]}]}